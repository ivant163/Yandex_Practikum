{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import lightgbm as lgb\n",
    "import lightgbm\n",
    "import time \n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from catboost import cv\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn. model_selection import LeaveOneOut\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier, Booster\n",
    "from numpy import mean\n",
    "from numpy import absolute\n",
    "from numpy import sqrt\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from pymystem3 import Mystem\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import brown\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "RANDOMSTATE = 12345\n",
    "STOPWORDS = set(nltk_stopwords.words('english'))\n",
    "\n",
    "def clear_text(text):\n",
    "    text = re.sub(r\"(?:\\n|\\r)\", \" \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z ]+\", \"\", text).strip()\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "#def lemmatize(text):\n",
    "#    m = Mystem()\n",
    "#    lemm_list = m.lemmatize(text)\n",
    "#    lemm_text = \"\".join(lemm_list)\n",
    "#    return lemm_text\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def lemmatize(text): \n",
    "    m = nltk.word_tokenize(text)\n",
    "    return ' '.join([lemmatizer.lemmatize(x) for x in m])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подключил библиотеки и определил переменные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузил датасет и сохранил его в переменной data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>\"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>bbq \\n\\nbe a man and lets discuss it-maybe ove...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Before you start throwing accusations and warn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Oh, and the girl above started her arguments w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                               text  toxic\n",
       "0            0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1            1  D'aww! He matches this background colour I'm s...      0\n",
       "2            2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3            3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4            4  You, sir, are my hero. Any chance you remember...      0\n",
       "5            5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6            6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7            7  Your vandalism to the Matt Shirvington article...      0\n",
       "8            8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9            9  alignment on this subject and which are contra...      0\n",
       "10          10  \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...      0\n",
       "11          11  bbq \\n\\nbe a man and lets discuss it-maybe ove...      0\n",
       "12          12  Hey... what is it..\\n@ | talk .\\nWhat is it......      1\n",
       "13          13  Before you start throwing accusations and warn...      0\n",
       "14          14  Oh, and the girl above started her arguments w...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Просмотрел первые 5 значения в датасете, вижу что текст на английском языке, в тексте присутствуют разделите, знаки препинания, буквы в различном регистре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(clear_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразовал текст с помощью функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    explanation why the edits made under my userna...\n",
       "1    daww he matches this background colour im seem...\n",
       "2    hey man im really not trying to edit war its j...\n",
       "3    more i cant make any real suggestions on impro...\n",
       "4    you sir are my hero any chance you remember wh...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повторно просмотрел первые 5 значения в датасете, визуально качество текста улучшилось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for x in data['text']: \n",
    "    corpus.append(lemmatize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизировал текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explanation why the edits made under my username hardcore metallica fan were reverted they werent vandalism just closure on some gas after i voted at new york doll fac and please dont remove the template from the talk page since im retired now\n"
     ]
    }
   ],
   "source": [
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Просмотрел текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = corpus\n",
    "target = data['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделил признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size = 0.25, random_state = RANDOMSTATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбил выборку на обучающую и тестовую."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первой части своего проекта, я загрузил данные, проанализировал их, выполнил предобработку и подготовил выборки для обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words = STOPWORDS)\n",
    "\n",
    "features_train = count_tf_idf.fit_transform(features_train)\n",
    "features_test = count_tf_idf.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определил оценку TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Значение RMSE для RandomForestClassifier:  0.567\n",
      "CPU times: total: 5.66 s\n",
      "Wall time: 28.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipeline = Pipeline([('selector', SelectKBest()), ('model', RandomForestClassifier(random_state=RANDOMSTATE, class_weight='balanced'))])\n",
    "model_3 = GridSearchCV(estimator = pipeline, param_grid = {'selector__k':[3,4,5,6,7,8,9,10]}, n_jobs=-1, scoring='f1', cv=5, verbose=3)\n",
    "model_3.fit(features_train, target_train)\n",
    "model_3.best_estimator_.fit(features_train, target_train)\n",
    "\n",
    "print('Значение RMSE для RandomForestClassifier: {: 0.3f}'.format(model_3.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Значение f1 для LogisticRegression:  0.760\n",
      "CPU times: total: 6min 18s\n",
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_2 = LogisticRegression(random_state=RANDOMSTATE, class_weight='balanced')\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10], 'max_iter': [1000], 'solver':['lbfgs']}\n",
    "model_2 = GridSearchCV(model_2, param_grid, cv=5, verbose=1, scoring='f1')\n",
    "model_2.fit(features_train, target_train)\n",
    "model_2.best_estimator_.fit(features_train, target_train)\n",
    "\n",
    "print('Значение f1 для LogisticRegression: {: 0.3f}'.format(model_2.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во второй части своего проекта для тестовой и обучающей выборок я вычислил значение TF-IDF. Далее я обучил две модели RandomForestClassifier и LogisticRegression, для обучения я использовал различные гиперпараметры и учил модели на лучших параметрах.  \n",
    "Модель RandomForestClassifier показала результат меньше чем LogisticRegression.  \n",
    "Для проверки на тестовой выборке я возьму модель LogisticRegression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение f1 для LogisticRegression на test:  0.770\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 15 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = f1_score(target_test, model_2.predict(features_test))\n",
    "\n",
    "print('Значение f1 для LogisticRegression на test: {: 0.3f}'.format(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В третье части своего проекта я выполнил тестирование лучшей модели LogisticRegression. Значение f1 метрики на тестовой выборке составило 0.770, что является достаточным значением для успешного завершения работы."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
